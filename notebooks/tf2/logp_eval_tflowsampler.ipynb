{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAE logp sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "D-Fe5G8m1FTC",
    "outputId": "8f21ee4e-6ad4-4fe2-a7a5-0bad6eae0cde"
   },
   "outputs": [],
   "source": [
    "\n",
    "#To make tf 2.0 compatible with tf1.0 code, we disable the tf2.0 functionalities\n",
    "#tf.disable_eager_execution()\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import rcParams\n",
    "import sys\n",
    "import pickle\n",
    "from functools import partial\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams.update({'font.family' : 'lmodern', 'font.size': 16,                                                                                                                                                    \n",
    "                     'axes.labelsize': 16, 'legend.fontsize': 12, \n",
    "                     'xtick.labelsize': 16, 'ytick.labelsize': 16, 'axes.titlesize': 16,\n",
    "                     'axes.linewidth': 1.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-AEYmOsH1FTI"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_hub as hub\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "tf.__version__\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__, tfp.__version__, hub.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the trained modules and evaluating logp in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GI5FLHJsZLTV"
   },
   "outputs": [],
   "source": [
    "from pae.model_tf2 import get_prior, get_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V9oAjWb9ZLTc"
   },
   "outputs": [],
   "source": [
    "import pae.create_datasets as crd\n",
    "import pae.load_data as ld\n",
    "load_funcs=dict(mnist=ld.load_mnist, fmnist=ld.load_fmnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vxW5NtaPZLTi"
   },
   "outputs": [],
   "source": [
    "PROJECT_PATH = \"../../\" \n",
    "PARAMS_PATH = os.path.join(PROJECT_PATH,'params')\n",
    "\n",
    "param_file  = 'params_mnist_-1_10_vae10_AE_test_full_sigma'\n",
    "params      = pickle.load(open(os.path.join(PARAMS_PATH,param_file+'.pkl'),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params['module_dir']='../../modules/mnist/class-1/latent_size10/net_type_vae10/loss_AE/test_full_sigma'\n",
    "# params['data_dir']= '../../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_func                                          = partial(load_funcs[params['data_set']])\n",
    "x_train, y_train, x_valid, y_valid, x_test, y_test = load_func(params['data_dir'],flatten=True)\n",
    "\n",
    "if np.all(x_test)==None:\n",
    "    x_test=x_valid\n",
    "\n",
    "x_train = x_train/256.-0.5\n",
    "x_test  = x_test/256.-0.5\n",
    "x_valid = x_valid/256.-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_path   = os.path.join(params['module_dir'],'decoder')\n",
    "encoder_path     = os.path.join(params['module_dir'],'encoder')\n",
    "nvp_path         = os.path.join(params['module_dir'],'hybrid8_nepoch220')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_likelihood(decoder,sigma):\n",
    "    \n",
    "  \n",
    "    def likelihood(z):\n",
    "        mean = decoder({'z':z})['x']\n",
    "        return tfd.Independent(tfd.MultivariateNormalDiag(loc=mean,scale_diag=sigma))\n",
    "\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z_fill        = tf.Variable(tf.zeros((params['batch_size'],params['latent_size']),tf.float32),trainable=False)\n",
    "\n",
    "sigma         = params['full_sigma']\n",
    "sigma         = tf.cast(sigma,tf.float32)\n",
    "\n",
    "encoder       = hub.KerasLayer(encoder_path,trainable=False, signature_outputs_as_dict=True)\n",
    "decoder       = hub.KerasLayer(generator_path, trainable=False, signature_outputs_as_dict=True)\n",
    "nvp_funcs     = hub.KerasLayer(nvp_path, trainable=False, signature_outputs_as_dict=True)\n",
    "\n",
    "likelihood    = get_likelihood(decoder,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "colab_type": "code",
    "id": "yvTEYw44O_5q",
    "outputId": "898dcdf7-f38f-4dae-a3aa-4f32a487f0ae"
   },
   "outputs": [],
   "source": [
    "def get_encoded(x):\n",
    "    return encoder({'x':x})['z']\n",
    "\n",
    "def get_decoded(z):\n",
    "    return decoder({'z':z})['x']\n",
    "\n",
    "def likelihood_eval(z,x,likelihood):\n",
    "    likelihood    = likelihood(z).log_prob(x)\n",
    "    return likelihood\n",
    "\n",
    "def prior_eval(z,nvp_funcs=nvp_funcs):\n",
    "    prior         = nvp_funcs({'z_sample':z,'sample_size':1, 'u_sample':np.zeros((1,params['latent_size']))})['log_prob']\n",
    "    return prior\n",
    "\n",
    "def posterior_eval(z,x,likelihood, nvp_funcs):\n",
    "    likelihood   = likelihood_eval(z,x,likelihood)\n",
    "    prior        = get_prior(params['latent_size'])\n",
    "    prior        = prior_eval(z, nvp_funcs)\n",
    "    logprob      = likelihood+prior\n",
    "    return logprob\n",
    "\n",
    "\n",
    "class LogP():\n",
    "    def __init__(self,x):\n",
    "        self.x = x\n",
    "        self.z_fill = tf.Variable(tf.zeros((params['batch_size'],params['latent_size']),tf.float32),trainable=False)\n",
    "        \n",
    "\n",
    "    def logp_grad(self,z):\n",
    "\n",
    "        self.z_fill[0].assign(z)\n",
    "        z_  = tf.convert_to_tensor(self.z_fill)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(z_)\n",
    "            log_p         = posterior_eval(z_,LP.x,likelihood,nvp_funcs)\n",
    "\n",
    "        grad = tape.gradient(log_p, [z_])[0]\n",
    "        return log_p[0], grad[0]\n",
    "\n",
    "    @tf.custom_gradient\n",
    "    def logp(self,z):\n",
    "\n",
    "        logp, grads = self.logp_grad(z)\n",
    "\n",
    "        def grad(up,variables=None):\n",
    "\n",
    "            grad_ = up*grads\n",
    "\n",
    "            return grad_, [None for ii in range(len(variables))] \n",
    "\n",
    "        return logp, grad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_ini = get_encoded(x_valid[0:16])[:,:10]\n",
    "z_ini.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LP = LogP(x_valid[0:16])\n",
    "z_ = tf.constant(z_ini[0])\n",
    "with tf.GradientTape() as g:\n",
    "    g.watch(z_)\n",
    "    y = LP.logp(z_)\n",
    "print(y,g.gradient(y, z_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimize -logp, starting from encoded value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "z_var     = tf.Variable(z_ini[0])\n",
    "losses    = []\n",
    "# z         = z_ini[0]\n",
    "for iteration in tqdm(range(300)):\n",
    "    optimizer.minimize(lambda: -LP.logp(z_var), var_list=[z_var])\n",
    "    loss  = -LP.logp(z_var)\n",
    "#     grads = logp_grad(z,negative=True)\n",
    "#     loss  = logp(z,negative=True)\n",
    "#     optimizer.apply_gradients(zip(grads, [z_var]))   \n",
    "    losses.append(loss)\n",
    "z_min = tf.convert_to_tensor(z_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.asarray(losses)\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_container(z):\n",
    "    filler = np.zeros((params['batch_size'],len(z)))\n",
    "    filler[0] = z\n",
    "    return filler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_esti = np.reshape(get_decoded(build_container(z_min))[0], (28,28))\n",
    "x_ini  = np.reshape(get_decoded(z_ini)[0], (28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tts2_qqiZLUR"
   },
   "outputs": [],
   "source": [
    "plt.title('best estimate')\n",
    "plt.imshow(np.reshape(x_esti, (28,28)))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.title('encoded')\n",
    "plt.imshow(np.reshape(x_ini,(28,28)))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.title('truth')\n",
    "plt.imshow(x_valid[0].reshape(28,28))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.title('truth-best estimate')\n",
    "plt.imshow(x_valid[0].reshape(28,28)-x_esti.reshape(28,28))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.title('truth-encoded')\n",
    "plt.imshow(x_valid[0].reshape(28,28)-x_ini.reshape(28,28))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.title('encoded-best estimate')\n",
    "plt.imshow(x_ini.reshape(28,28)-x_esti.reshape(28,28))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print('summed square error after and before optimization')\n",
    "print(np.sum((x_valid[0].reshape(28,28)-x_esti.reshape(28,28))**2),np.sum((x_valid[0].reshape(28,28)-x_ini.reshape(28,28))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the HMC transition kernel.\n",
    "num_results = int(10)\n",
    "num_burnin_steps = int(1)\n",
    "\n",
    "adaptive_hmc = tfp.mcmc.SimpleStepSizeAdaptation(\n",
    "    tfp.mcmc.HamiltonianMonteCarlo(\n",
    "        target_log_prob_fn=LP.logp,\n",
    "        num_leapfrog_steps=3,\n",
    "        step_size=1.),\n",
    "    num_adaptation_steps=int(num_burnin_steps * 0.8))\n",
    "\n",
    "# Run the chain (with burn-in).\n",
    "@tf.function\n",
    "def run_chain():\n",
    "  # Run the chain (with burn-in).\n",
    "    samples, is_accepted = tfp.mcmc.sample_chain(\n",
    "      num_results      = num_results,\n",
    "      num_burnin_steps = num_burnin_steps,\n",
    "      current_state    = z_min,\n",
    "      kernel           = adaptive_hmc,\n",
    "      trace_fn         = lambda _, pkr: pkr.inner_results.is_accepted)\n",
    "\n",
    "    sample_mean = tf.reduce_mean(samples)\n",
    "    sample_stddev = tf.math.reduce_std(samples)\n",
    "    is_accepted = tf.reduce_mean(tf.cast(is_accepted, dtype=tf.float32))\n",
    "    return sample_mean, sample_stddev, is_accepted\n",
    "\n",
    "sample_mean, sample_stddev, is_accepted = run_chain()\n",
    "\n",
    "print('mean:{:.4f}  stddev:{:.4f}  acceptance:{:.4f}'.format(\n",
    "    sample_mean.numpy(), sample_stddev.numpy(), is_accepted.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "LambdaNetwork.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf22",
   "language": "python",
   "name": "tf22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
