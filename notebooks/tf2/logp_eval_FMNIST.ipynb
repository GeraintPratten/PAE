{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAE logp sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "D-Fe5G8m1FTC",
    "outputId": "8f21ee4e-6ad4-4fe2-a7a5-0bad6eae0cde"
   },
   "outputs": [],
   "source": [
    "\n",
    "#To make tf 2.0 compatible with tf1.0 code, we disable the tf2.0 functionalities\n",
    "#tf.disable_eager_execution()\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import rcParams\n",
    "import sys\n",
    "import pickle\n",
    "from functools import partial\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams.update({'font.family' : 'lmodern', 'font.size': 16,                                                                                                                                                    \n",
    "                     'axes.labelsize': 16, 'legend.fontsize': 12, \n",
    "                     'xtick.labelsize': 16, 'ytick.labelsize': 16, 'axes.titlesize': 16,\n",
    "                     'axes.linewidth': 1.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-AEYmOsH1FTI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_hub as hub\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "tf.__version__\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0 0.10.0 0.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__, tfp.__version__, hub.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the trained modules and evaluating logp in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GI5FLHJsZLTV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V9oAjWb9ZLTc"
   },
   "outputs": [],
   "source": [
    "import pae.create_datasets as crd\n",
    "import pae.load_data as ld\n",
    "load_funcs=dict(mnist=ld.load_mnist, fmnist=ld.load_fmnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vxW5NtaPZLTi"
   },
   "outputs": [],
   "source": [
    "\n",
    "PARAMS_PATH = '/global/cscratch1/sd/vboehm/PAE_samples/FMNIST/latent_dim64/modules/'\n",
    "\n",
    "param_file  = 'params_fmnist_-1_64_infoGAN_AE_v2rot_full_sigma'\n",
    "params      = pickle.load(open(os.path.join(PARAMS_PATH,param_file+'.pkl'),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params['module_dir']='../../modules/mnist/class-1/latent_size10/net_type_vae10/loss_AE/test_full_sigma'\n",
    "# params['data_dir']= '../../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_func                                          = partial(load_funcs[params['data_set']])\n",
    "x_train, y_train, x_valid, y_valid, x_test, y_test = load_func(params['data_dir'],flatten=False)\n",
    "\n",
    "if np.all(x_test)==None:\n",
    "    x_test=x_valid\n",
    "\n",
    "x_train = (x_train/256.-0.5).astype(np.float32)\n",
    "x_test  = (x_test/256.-0.5).astype(np.float32)\n",
    "x_valid = (x_valid/256.-0.5).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_func                                          = partial(load_funcs['mnist'])\n",
    "x_train_ood, y_train, x_valid_ood, y_valid, x_test_ood, y_test = load_func(params['data_dir'],flatten=False)\n",
    "\n",
    "\n",
    "x_train_ood = (x_train_ood/256.-0.5).astype(np.float32)\n",
    "x_test_ood  = (x_test_ood/256.-0.5).astype(np.float32)\n",
    "x_valid_ood = (x_valid_ood/256.-0.5).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../modules/fmnist/class-1/latent_size64/net_type_infoGAN/loss_AE/v2rot_full_sigma'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['module_dir']='/global/cscratch1/sd/vboehm/PAE_samples/FMNIST/latent_dim64/modules/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_path   = os.path.join(params['module_dir'],'decoder')\n",
    "encoder_path     = os.path.join(params['module_dir'],'encoder')\n",
    "nvp_path         = os.path.join(params['module_dir'],'hybrid1_nepoch100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_likelihood(decoder,sigma):\n",
    "    sigma = tf.reshape(sigma,(params['batch_size'],-1))\n",
    "    def likelihood(z):\n",
    "        mean  = decoder({'z':z})['x']\n",
    "        mean  = tf.reshape(mean,(params['batch_size'],-1))\n",
    "        \n",
    "        LL = tfd.MultivariateNormalDiag(loc=mean,scale_diag=sigma)\n",
    "        return tfd.Independent(LL)\n",
    "\n",
    "    return likelihood\n",
    "\n",
    "def get_prior(latent_size):\n",
    "    return tfd.MultivariateNormalDiag(tf.zeros(latent_size), scale_identity_multiplier=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#z_fill        = tf.Variable(tf.zeros((params['batch_size'],params['latent_size']),tf.float32),trainable=False)\n",
    "\n",
    "sigma         = params['full_sigma']\n",
    "sigma         = sigma.astype(np.float32)\n",
    "print(sigma.shape)\n",
    "encoder       = hub.KerasLayer(encoder_path,trainable=False, signature_outputs_as_dict=True)\n",
    "decoder       = hub.KerasLayer(generator_path, trainable=False, signature_outputs_as_dict=True)\n",
    "nvp_funcs     = hub.KerasLayer(nvp_path, trainable=False, signature_outputs_as_dict=True)\n",
    "\n",
    "likelihood    = get_likelihood(decoder,np.repeat(np.expand_dims(sigma,0),params['batch_size'],axis=0))\n",
    "prior         = get_prior(params['latent_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "colab_type": "code",
    "id": "yvTEYw44O_5q",
    "outputId": "898dcdf7-f38f-4dae-a3aa-4f32a487f0ae"
   },
   "outputs": [],
   "source": [
    "def get_encoded(x):\n",
    "    mu, sigma        = tf.split(encoder({'x':x})['z'], 2, axis=-1)\n",
    "    return mu\n",
    "\n",
    "def get_decoded(z):\n",
    "    return decoder({'z':z})['x']\n",
    "\n",
    "def likelihood_eval(z,x,likelihood):\n",
    "    likelihood    = likelihood(z).log_prob(x)\n",
    "    return likelihood\n",
    "\n",
    "def NF_prior_eval(z,nvp_funcs=nvp_funcs):\n",
    "    prior         = nvp_funcs({'z_sample':z,'sample_size':1, 'u_sample':np.zeros((1,params['latent_size']))})['log_prob']\n",
    "    return prior\n",
    "\n",
    "def posterior_eval(z,x,likelihood, nvp_funcs):\n",
    "    x            = tf.reshape(x,(params['batch_size'],-1))\n",
    "    likelihood   = likelihood_eval(z,x,likelihood)\n",
    "    NF_prior     = prior_eval(z, nvp_funcs)\n",
    "    logprob      = likelihood+NF_prior\n",
    "    return logprob\n",
    "\n",
    "def Jacobian_eval(z,nvp_funcs):\n",
    "    NF_prior = NF_prior_eval(z,nvp_funcs=nvp_funcs)\n",
    "    J        = NF_prior-prior.log_prob(z)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_hub.keras_layer.KerasLayer at 0x2aab37c165b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load(os.path.join('/global/cscratch1/sd/vboehm/PAE_samples/FMNIST/latent_dim64/samples','HMC_MNIST_latent_dim64_burnin50_leapfrog3_2.npy'),allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriors = np.zeros(samples.shape[:-1])\n",
    "\n",
    "num_chunks = len(posteriors)//params['batch_size']\n",
    "\n",
    "for ii in range(num_chunks):\n",
    "    for jj in range(25):\n",
    "        z  = samples[ii*params['batch_size']:(ii+1)*params['batch_size'],jj]\n",
    "        post = posterior_eval(z,x_test[ii*params['batch_size']:(ii+1)*params['batch_size']],likelihood, nvp_funcs)\n",
    "        posteriors[ii*params['batch_size']:(ii+1)*params['batch_size'],jj]=post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3200, 25, 64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "LambdaNetwork.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf22",
   "language": "python",
   "name": "tf22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
